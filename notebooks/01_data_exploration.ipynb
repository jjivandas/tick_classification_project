{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4a7cb37",
   "metadata": {},
   "source": [
    "## Setting up imports and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48acb592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# --- Configuration ---\n",
    "# Define the paths to your data\n",
    "METADATA_PATH = '../data/raw/annotations.csv'\n",
    "IMAGE_DIR = '../data/raw/Tick_Images-6_25_25'\n",
    "OUTPUT_JSON_PATH = '../data/processed/final_data.json'\n",
    "CLASS_NAMES_PATH = '../data/processed/class_names.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebb4bd0",
   "metadata": {},
   "source": [
    "## Loading in the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91637293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 374 records from the metadata file.\n",
      "Found 1056 image files to search through.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tc/csl5ykwn1v36vwqf20swsn880000gn/T/ipykernel_73037/4201957005.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.fillna('', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the data from your CSV into a DataFrame.\n",
    "df = pd.read_csv(METADATA_PATH)\n",
    "df.fillna('', inplace=True)\n",
    "# removing duplicates based on 'Sample ID'\n",
    "df.drop_duplicates(subset=['Sample ID'], keep='first', inplace=True)\n",
    "\n",
    "# 2. Get All Available Image Filenames\n",
    "# Get a set of all available image filenames for fast lookups.\n",
    "# We convert all filenames to uppercase to handle potential inconsistencies (e.g., .jpg vs .JPG).\n",
    "all_image_files = {f.upper(): f for f in os.listdir(IMAGE_DIR)}\n",
    "\n",
    "print(f\"Loaded {len(df)} records from the metadata file.\")\n",
    "print(f\"Found {len(all_image_files)} image files to search through.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34e357df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Determine the Final List of Valid IDs ---\n",
    "csv_ids = set(df['Sample ID'].astype(str)) # only unique IDs from the CSV\n",
    "image_base_ids = {f.upper().rsplit('-', 1)[0] for f in all_image_files}\n",
    "valid_ids = csv_ids.intersection(image_base_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eabe4010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated. Proceeding to create JSON for 370 specimens.\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Filter DataFrame to Final Valid Set ---\n",
    "final_df = df[df['Sample ID'].isin(valid_ids)].copy()\n",
    "print(f\"Validated. Proceeding to create JSON for {len(final_df)} specimens.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03b8b582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 738 total entries for the JSON file.\n",
      "Missing images for 1 specimens: ['246-01']\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Build the JSON Structure ---\n",
    "final_data_list = []\n",
    "class_names_set = set()\n",
    "missing_ids = []\n",
    "\n",
    "for index, row in final_df.iterrows():\n",
    "    base_id = row['Sample ID'].upper()\n",
    "    dorsal_path, ventral_path = None, None\n",
    "\n",
    "    dorsal_patterns = [f\"{base_id}-01.JPG\", f\"{base_id}-1.JPG\"]\n",
    "    ventral_patterns = [f\"{base_id}-02.JPG\", f\"{base_id}-2.JPG\"]\n",
    "\n",
    "    for pattern in dorsal_patterns:\n",
    "        if pattern in all_image_files:\n",
    "            original_filename = all_image_files[pattern]\n",
    "            dorsal_path = os.path.join(IMAGE_DIR, original_filename)\n",
    "            break\n",
    "    for pattern in ventral_patterns:\n",
    "        if pattern in all_image_files:\n",
    "            original_filename = all_image_files[pattern]\n",
    "            ventral_path = os.path.join(IMAGE_DIR, original_filename)\n",
    "            break\n",
    "\n",
    "    if dorsal_path and ventral_path:\n",
    "        final_data_list.append({\n",
    "            'image_path': dorsal_path,\n",
    "            'true_label': row['Species of Tick'],\n",
    "            'sample_id': row['Sample ID'],\n",
    "            'view': 'dorsal',\n",
    "            'sex': row.get('Tick Sex1'),\n",
    "            'life_stage': row.get('Life Stage'),\n",
    "            'attached': row.get('Attached?')\n",
    "        })\n",
    "        final_data_list.append({\n",
    "            'image_path': ventral_path,\n",
    "            'true_label': row['Species of Tick'],\n",
    "            'sample_id': row['Sample ID'],\n",
    "            'view': 'ventral',\n",
    "            'sex': row.get('Tick Sex1'),\n",
    "            'life_stage': row.get('Life Stage'),\n",
    "            'attached': row.get('Attached?')\n",
    "        })\n",
    "        class_names_set.add(row['Species of Tick'])\n",
    "    else:\n",
    "        missing_ids.append(row['Sample ID'])\n",
    "\n",
    "print(f\"Created {len(final_data_list)} total entries for the JSON file.\")\n",
    "if missing_ids:\n",
    "    print(f\"Missing images for {len(missing_ids)} specimens: {missing_ids}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee536503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Data manifest saved to: ../data/processed/final_data.json\n",
      "Success! Found 7 unique class names and saved them to: ../data/processed/class_names.json\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Save the JSON File ---\n",
    "output_file = os.path.join(os.path.dirname(OUTPUT_JSON_PATH), \"final_data.json\")\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(final_data_list, f, indent=4)\n",
    "\n",
    "print(f\"Success! Data manifest saved to: {output_file}\")\n",
    "\n",
    "# Convert the class names set to a sorted list for consistent order\n",
    "final_class_names = sorted(list(class_names_set))\n",
    "with open(CLASS_NAMES_PATH, 'w') as f:\n",
    "    json.dump(final_class_names, f, indent=4)\n",
    "\n",
    "print(f\"Success! Found {len(final_class_names)} unique class names and saved them to: {CLASS_NAMES_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1808ba",
   "metadata": {},
   "source": [
    "## Getting number of Specimens in each resource. Checks for duplicates and missing datapoints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62b68685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 374 unique Sample IDs in the CSV file.\n",
      "Found 530 unique base IDs from the image filenames.\n",
      "\n",
      "--- DIAGNOSTIC RESULTS ---\n",
      "\n",
      "ðŸš¨ Found 4 IDs in the CSV that have NO matching image base ID:\n",
      "['ZOE-0086-01', 'ZOE-0091-01', 'ZOE-0082-07', 'ZOE-0070-01']\n",
      "------------------------------\n",
      "ðŸš¨ Found 160 image base IDs that are NOT in the CSV:\n",
      "['69-02', '370-01', '38-02', '47-02', '46-05', '347-01', '34-02', '29-02', '66-01', '363-01', '43-12', '27-01', '55-06', '54-02', '45-04', '364-01', '54-06', '19-01', '45-03', '45-05', '28-01', '46-02', '53-04', '43-16', '42-02', '43-09', '55-01', '46-04', '366-01', '41-05', '39-01', '56-04', '48-02', '35-03', '41-03', '376-01', '61-03', '43-01', '55-03', '66-05', '59-01', '66-03', '362-01', '47-01', '33-02', '41-04', 'ZOE-0023-01', '41-01', '67-02', '37-05', '54-01', '45-02', '54-11', '66-07', '37-06', '365-01', '31-02', '66-08', '43-04', '66-06', '33-01', '55-10', '42-01', '43-15', '54-04', '37-02', '36-01', '43-10', '34-01', '61-01', 'ZOE-0023-02', '55-08', '37-03', '52-01', '55-02', '286-00', '43-05', '51-01', '46-01', '34-03', '50-01', '55-04', '43-02', '55-09', '37-01', '63-01', '48-01', '70-01', '56-06', '46-03', '35-01', '31-01', '54-10', '54-07', '32-01', '366-1', '38-01', '43-08', '43-11', '62-03', '62-02', '30-02', '43-07', '38-03', '43-13', '52-03', '37-07', '55-05', '40-01', 'ZOE-0023-03', '50-03', '52-02', '45-01', '58-01', '59-03', '53-01', '66-04', '59-02', '53-03', '31-03', '53-02', '54-08', '49-03', '44-01', '27-02', '53-05', '49-01', '30-01', '40-02', '51-02', '41-06', '66-02', '54-05', '43-06', '62-01', '55-07', '56-02', '365-02', '37-04', '61-02', '29-01', '54-03', '41-02', '43-14', '43-03', '57-01', '56-05', '47-03', '49-02', 'ZOE-0086-02', '69-01', '49-04', '36-02', '35-02', '49-05', '54-09', '50-02', '56-01', '372-01', '56-03']\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Get all Sample IDs from the CSV ---\n",
    "# This is our \"source of truth\".\n",
    "df = pd.read_csv(METADATA_PATH)\n",
    "csv_ids = set(df['Sample ID'].astype(str))\n",
    "print(f\"Found {len(csv_ids)} unique Sample IDs in the CSV file.\")\n",
    "\n",
    "# --- Step 2: Get all base IDs from the image filenames ---\n",
    "# This is what's actually in our image folder.\n",
    "image_base_ids = set()\n",
    "for filename in os.listdir(IMAGE_DIR):\n",
    "    # We split \"ZOE-0013-09-01.JPG\" and take the first 3 parts\n",
    "    parts = filename.split('-')\n",
    "    if len(parts) >= 3:\n",
    "        # Rejoin to form the base ID, e.g., \"ZOE-0013-09\"\n",
    "        base_id = '-'.join(parts[:-1]) # Takes all parts except the last one\n",
    "        image_base_ids.add(base_id)\n",
    "\n",
    "print(f\"Found {len(image_base_ids)} unique base IDs from the image filenames.\")\n",
    "\n",
    "# --- Step 3: Find the Mismatches ---\n",
    "# This is the most important part. We find what's in one list but not the other.\n",
    "\n",
    "missing_from_images = csv_ids.difference(image_base_ids)\n",
    "missing_from_csv = image_base_ids.difference(csv_ids)\n",
    "\n",
    "print(\"\\n--- DIAGNOSTIC RESULTS ---\\n\")\n",
    "\n",
    "if not missing_from_images:\n",
    "    print(\"âœ… All Sample IDs from the CSV have a corresponding image base ID.\")\n",
    "else:\n",
    "    print(f\"ðŸš¨ Found {len(missing_from_images)} IDs in the CSV that have NO matching image base ID:\")\n",
    "    # Print the first 10 examples so we can inspect them\n",
    "    print(list(missing_from_images)[:10])\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "if not missing_from_csv:\n",
    "    print(\"âœ… All image base IDs have a corresponding entry in the CSV.\")\n",
    "else:\n",
    "    print(f\"ðŸš¨ Found {len(missing_from_csv)} image base IDs that are NOT in the CSV:\")\n",
    "    # Print the first 10 examples\n",
    "    print(list(missing_from_csv)[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b751f9",
   "metadata": {},
   "source": [
    "## Checking how many Specimens have only 1 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aad18ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- IMAGE COUNT ANALYSIS ---\n",
      "Total unique base IDs found: 530\n",
      "\n",
      " Found 4 specimens with only ONE image:\n",
      "{'286-00': 1, '366-1': 1, '246-01': 1, '33-01': 1}\n"
     ]
    }
   ],
   "source": [
    "# We'll reuse the 'image_base_ids' logic from our diagnostic script,\n",
    "# but this time we'll count the occurrences.\n",
    "from collections import Counter\n",
    "\n",
    "image_id_counts = []\n",
    "for filename in os.listdir(IMAGE_DIR):\n",
    "    parts = filename.split('-')\n",
    "    if len(parts) >= 3:\n",
    "        base_id = '-'.join(parts[:-1])\n",
    "        image_id_counts.append(base_id)\n",
    "\n",
    "# Count how many times each base_id appears\n",
    "id_counts = Counter(image_id_counts)\n",
    "\n",
    "# Now, find the IDs that don't have exactly 2 images\n",
    "specimens_with_one_image = {id: count for id, count in id_counts.items() if count == 1}\n",
    "specimens_with_more_than_two = {id: count for id, count in id_counts.items() if count > 2}\n",
    "\n",
    "\n",
    "print(\"--- IMAGE COUNT ANALYSIS ---\")\n",
    "print(f\"Total unique base IDs found: {len(id_counts)}\")\n",
    "\n",
    "if specimens_with_one_image:\n",
    "    print(f\"\\n Found {len(specimens_with_one_image)} specimens with only ONE image:\")\n",
    "    print(specimens_with_one_image)\n",
    "else:\n",
    "    print(\"\\n All specimens appear to have at least two images.\")\n",
    "\n",
    "if specimens_with_more_than_two:\n",
    "    print(f\"\\n Found {len(specimens_with_more_than_two)} specimens with MORE than two images:\")\n",
    "    print(specimens_with_more_than_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496e9d43",
   "metadata": {},
   "source": [
    "## Matching the images with the available data and building the JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fee10234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data_list = []\n",
    "# records_with_missing_images = []\n",
    "\n",
    "# # Iterate through each row of the metadata DataFrame.\n",
    "# for index, row in df.iterrows():\n",
    "#     # Get the complete identifier directly from the 'Sample ID' column.\n",
    "#     base_id = row['Sample ID']\n",
    "\n",
    "#     # Construct the expected dorsal and ventral filenames (converted to uppercase for matching).\n",
    "#     dorsal_filename = f\"{base_id}-01.JPG\" or f\"{base_id}-1.JPG\"\n",
    "#     ventral_filename = f\"{base_id}-02.JPG\"\n",
    "\n",
    "#     # Check if both uppercase filenames exist in our set of actual filenames.\n",
    "#     if dorsal_filename in all_image_filenames and ventral_filename in all_image_filenames:\n",
    "        \n",
    "#         # Create the dictionary for the DORSAL image.\n",
    "#         dorsal_entry = {\n",
    "#             'image_path': os.path.join(IMAGE_DIR, dorsal_filename),\n",
    "#             'true_label': row['Species of Tick'],\n",
    "#             'sample_id': row['Sample ID'],\n",
    "#             'view': 'dorsal',\n",
    "#             'sex': row.get('Sex'),\n",
    "#             'life_stage': row.get('Life Stage'),\n",
    "#             'attached': row.get('Attached?')\n",
    "#         }\n",
    "#         final_data_list.append(dorsal_entry)\n",
    "\n",
    "#         # Create the dictionary for the VENTRAL image.\n",
    "#         ventral_entry = {\n",
    "#             'image_path': os.path.join(IMAGE_DIR, ventral_filename),\n",
    "#             'true_label': row['Species of Tick'],\n",
    "#             'sample_id': row['Sample ID'],\n",
    "#             'view': 'ventral',\n",
    "#             'sex': row.get('Sex'),\n",
    "#             'life_stage': row.get('Life Stage'),\n",
    "#             'attached': row.get('Attached?')\n",
    "#         }\n",
    "#         final_data_list.append(ventral_entry)\n",
    "#     else:\n",
    "#         # If one or both images are missing, log the record for review.\n",
    "#         records_with_missing_images.append(base_id)\n",
    "\n",
    "# print(f\"Successfully created {len(final_data_list)} data entries for the JSON file.\")\n",
    "# if records_with_missing_images:\n",
    "#     print(f\"\\nWarning: Could not find image pairs for the following {len(records_with_missing_images)} records:\")\n",
    "#     print(records_with_missing_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
