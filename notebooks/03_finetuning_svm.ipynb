{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e2c5f9d",
   "metadata": {},
   "source": [
    "## 0. Imports and code config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d30e6522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding cache dir: /Users/jayjivandas/Research_Imageomics/BioClip/tick_classification_project/data/processed/emb_cache\n",
      "Results root dir: /Users/jayjivandas/Research_Imageomics/BioClip/tick_classification_project/results/svm_bioclip\n",
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# === 0) Imports & core config ===\n",
    "# !pip install -q pybioclip scikit-learn pandas numpy pillow torch\n",
    "\n",
    "import json, random, hashlib, os\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "# BioCLIP: used as a feature extractor (image -> embedding vector)\n",
    "from bioclip.predict import BaseClassifier\n",
    "\n",
    "# ---- paths (adjust these if needed) ----\n",
    "CLASS_NAMES = \"../data/processed/class_names_no_ixodes.json\"   # species list\n",
    "DATA   = \"../data/processed/final_data_no_ixodes.json\"    # manifest with image_path, true_label, sample_id, view\n",
    "\n",
    "# ---- few-shot split params ----\n",
    "K         = 5     # train specimens per species\n",
    "MIN_TOTAL = 6     # species must have >=6 specimens (so >=1 test)\n",
    "SEED      = 0     # seed for single dry run; we’ll add 0..99 later\n",
    "\n",
    "# ---- per-image embedding cache (under data/processed/) ----\n",
    "EMB_CACHE = Path(\"..\") / \"data\" / \"processed\" / \"emb_cache\"\n",
    "EMB_CACHE.mkdir(parents=True, exist_ok=True)  # create if missing\n",
    "print(\"Embedding cache dir:\", EMB_CACHE.resolve())\n",
    "\n",
    "# ---- per-seed results root (under data/processed/) ----\n",
    "RESULTS_ROOT = Path(\"..\") / \"results\" / \"svm_bioclip\"\n",
    "RESULTS_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "print(\"Results root dir:\", RESULTS_ROOT.resolve())\n",
    "\n",
    "# ---- device + model init ----\n",
    "DEVICE = \"mps\" if torch.backends.mps.is_available() else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BC = BaseClassifier(device=DEVICE)\n",
    "\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca784ccf",
   "metadata": {},
   "source": [
    "## 1. Load classes and Specimens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "92cf23f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Included species: 5\n",
      "Total usable specimens (both views, species >= 6): 578\n",
      "Amblyomma americanum: 90 specimens\n",
      "Amblyomma maculatum: 6 specimens\n",
      "Dermacentor variabilis: 308 specimens\n",
      "Haemaphysalis longicornis: 35 specimens\n",
      "Ixodes scapularis: 139 specimens\n"
     ]
    }
   ],
   "source": [
    "# === Block 1 — Load Classes and Data → Build Specimen Index ===\n",
    "\n",
    "# 1) Load class list and data\n",
    "with open(CLASS_NAMES, \"r\") as f:   # CLASS_NAMES was set in Block 0 to the JSON path\n",
    "    SPECIES_LIST = set(json.load(f))  # species names we care about\n",
    "\n",
    "with open(DATA, \"r\") as f:          # DATA was set in Block 0 to the JSON path\n",
    "    data = json.load(f)             # list of records (image_path, true_label, sample_id, view)\n",
    "\n",
    "# 2) Build specimen index:\n",
    "#    by_species[species][sample_id] -> {\"dorsal\": <path>, \"ventral\": <path>}\n",
    "by_species = defaultdict(lambda: defaultdict(dict))\n",
    "for r in data:\n",
    "    sp = r[\"true_label\"]\n",
    "    if sp not in SPECIES_LIST:\n",
    "        continue\n",
    "    sid  = r[\"sample_id\"]\n",
    "    view = str(r[\"view\"]).strip().lower()\n",
    "    by_species[sp][sid][view] = r[\"image_path\"]\n",
    "\n",
    "# 3) Keep only specimens with BOTH views\n",
    "for sp in list(by_species.keys()):\n",
    "    for sid in list(by_species[sp].keys()):\n",
    "        views = by_species[sp][sid]\n",
    "        if not (\"dorsal\" in views and \"ventral\" in views):\n",
    "            del by_species[sp][sid]\n",
    "    if not by_species[sp]:\n",
    "        del by_species[sp]\n",
    "\n",
    "# 4) Keep only species with >= MIN_TOTAL specimens\n",
    "for sp in list(by_species.keys()):\n",
    "    if len(by_species[sp]) < MIN_TOTAL:\n",
    "        del by_species[sp]\n",
    "\n",
    "included_species = sorted(by_species.keys())\n",
    "\n",
    "# 5) Quick summary\n",
    "n_specimens = sum(len(smap) for smap in by_species.values())\n",
    "print(f\"Included species: {len(included_species)}\")\n",
    "print(f\"Total usable specimens (both views, species >= {MIN_TOTAL}): {n_specimens}\")\n",
    "\n",
    "# Optional: per-species counts\n",
    "species_counts = {sp: len(smap) for sp, smap in by_species.items()}\n",
    "for sp in included_species:\n",
    "    print(f\"{sp}: {species_counts[sp]} specimens\")\n",
    "\n",
    "assert len(included_species) > 0, \"No species meet the criteria (both views and MIN_TOTAL).\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c93ea77",
   "metadata": {},
   "source": [
    "## Block 2 Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2271440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 0\n",
      "Species included: 5\n",
      "Train specimens: 25  (expected 5 × 5 = 25)\n",
      "Test specimens:  553\n",
      "  Amblyomma americanum: total=90, train=5, test=85\n",
      "  Amblyomma maculatum: total=6, train=5, test=1\n",
      "  Dermacentor variabilis: total=308, train=5, test=303\n",
      "  Haemaphysalis longicornis: total=35, train=5, test=30\n",
      "  Ixodes scapularis: total=139, train=5, test=134\n",
      "  Train IDs sample — Amblyomma americanum: ['ZOE-0014-12', 'ZOE-0014-11', '201-01']\n",
      "  Train IDs sample — Amblyomma maculatum: ['GLN-0087-06', 'GLN-0087-10', 'GLN-0087-07']\n",
      "  Train IDs sample — Dermacentor variabilis: ['435-01', '359-01', '147-01']\n",
      "  Train IDs sample — Haemaphysalis longicornis: ['47-02', 'GLN-0087-15', 'OPL-0098-01']\n",
      "  Train IDs sample — Ixodes scapularis: ['55-10', '60-01', '221-01']\n"
     ]
    }
   ],
   "source": [
    "# === Block 2 — Train/Test Split (5-shot, Seeded, no leakage) ===\n",
    "\n",
    "def split_once(by_species, species_list, k=K, seed=SEED):\n",
    "    rng = random.Random(seed)\n",
    "    train_pairs, test_pairs = [], []\n",
    "    per_species_counts = {}\n",
    "\n",
    "    for sp in species_list:\n",
    "        sids = list(by_species[sp].keys())\n",
    "        rng.shuffle(sids)\n",
    "        tr, te = sids[:k], sids[k:]\n",
    "\n",
    "        # Sanity checks per your policy\n",
    "        assert len(tr) == k, f\"{sp}: needs exactly {k} train specimens, found {len(tr)}\"\n",
    "        assert len(te) >= 1, f\"{sp}: needs at least 1 test specimen (has {len(sids)} total)\"\n",
    "\n",
    "        train_pairs.extend([(sp, sid) for sid in tr])\n",
    "        test_pairs.extend([(sp, sid) for sid in te])\n",
    "        per_species_counts[sp] = {\"train\": len(tr), \"test\": len(te), \"total\": len(sids)}\n",
    "\n",
    "    # No leakage: specimen (sample_id) cannot be in both sets\n",
    "    assert not (set(train_pairs) & set(test_pairs)), \"Leakage detected: same (species, sample_id) in train & test\"\n",
    "\n",
    "    return train_pairs, test_pairs, per_species_counts\n",
    "\n",
    "train_pairs, test_pairs, split_counts = split_once(by_species, included_species, k=K, seed=SEED)\n",
    "\n",
    "# ---- Summary prints ----\n",
    "n_species = len(included_species)\n",
    "n_train   = len(train_pairs)\n",
    "n_test    = len(test_pairs)\n",
    "\n",
    "print(f\"Seed: {SEED}\")\n",
    "print(f\"Species included: {n_species}\")\n",
    "print(f\"Train specimens: {n_train}  (expected {K} × {n_species} = {K*n_species})\")\n",
    "print(f\"Test specimens:  {n_test}\")\n",
    "\n",
    "for sp in included_species:\n",
    "    c = split_counts[sp]\n",
    "    print(f\"  {sp}: total={c['total']}, train={c['train']}, test={c['test']}\")\n",
    "\n",
    "# Optional: peek a few chosen IDs per species (trim for readability)\n",
    "for sp in included_species:\n",
    "    chosen = [sid for (s, sid) in train_pairs if s == sp][:min(3, K)]\n",
    "    print(f\"  Train IDs sample — {sp}: {chosen}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6a7178",
   "metadata": {},
   "source": [
    "## Block 3: Embedding helpers, getting the embeddings and building our Cache. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ddff3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Block 3 — Embedding Helpers (Per-Image Cache + Specimen Vector) ===\n",
    "\n",
    "# Per-image cache filename (hash of the image path -> unique + reproducible)\n",
    "def _cache_fp(img_path: str) -> Path:\n",
    "    h = hashlib.sha256(img_path.encode(\"utf-8\")).hexdigest()[:24]\n",
    "    return EMB_CACHE / f\"{h}.npy\"\n",
    "\n",
    "# Single-image -> embedding (uses cache if available)\n",
    "def embed_image(img_path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Input:  path to an image file\n",
    "    Output: 1D numpy array (BioCLIP embedding), L2-normalized if normalize=True in create_image_features\n",
    "    \"\"\"\n",
    "    fp = _cache_fp(img_path)\n",
    "    if fp.exists():\n",
    "        return np.load(fp)\n",
    "    pil = Image.open(img_path).convert(\"RGB\")\n",
    "    vec = BC.create_image_features([pil], normalize=True).cpu().numpy()[0]\n",
    "    np.save(fp, vec)\n",
    "    return vec\n",
    "\n",
    "# Specimen-level vector: average dorsal + ventral embeddings -> one vector per specimen\n",
    "def specimen_vec(rec: dict) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    rec is: {\"dorsal\": <path>, \"ventral\": <path>}\n",
    "    Returns a single vector for the specimen: 0.5*(z_dorsal + z_ventral)\n",
    "    \"\"\"\n",
    "    z_d = embed_image(rec[\"dorsal\"])\n",
    "    z_v = embed_image(rec[\"ventral\"])\n",
    "    return 0.5 * (z_d + z_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a84604",
   "metadata": {},
   "source": [
    "## Block 4- build X/Y, Train SVM, Metrics, SINGLE SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55fd34d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.814\n",
      "Macro (balanced) accuracy: 0.814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZOE-0014-15</td>\n",
       "      <td>Amblyomma americanum</td>\n",
       "      <td>Amblyomma americanum</td>\n",
       "      <td>0.436862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150-01</td>\n",
       "      <td>Amblyomma americanum</td>\n",
       "      <td>Amblyomma americanum</td>\n",
       "      <td>0.453386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69-02</td>\n",
       "      <td>Amblyomma americanum</td>\n",
       "      <td>Amblyomma americanum</td>\n",
       "      <td>0.372667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31-02</td>\n",
       "      <td>Amblyomma americanum</td>\n",
       "      <td>Amblyomma americanum</td>\n",
       "      <td>0.360671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43-15</td>\n",
       "      <td>Amblyomma americanum</td>\n",
       "      <td>Amblyomma americanum</td>\n",
       "      <td>0.411300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34-01</td>\n",
       "      <td>Amblyomma americanum</td>\n",
       "      <td>Amblyomma americanum</td>\n",
       "      <td>0.478879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>61-01</td>\n",
       "      <td>Amblyomma americanum</td>\n",
       "      <td>Amblyomma americanum</td>\n",
       "      <td>0.387920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>40-01</td>\n",
       "      <td>Amblyomma americanum</td>\n",
       "      <td>Amblyomma americanum</td>\n",
       "      <td>0.416312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>465-01</td>\n",
       "      <td>Amblyomma americanum</td>\n",
       "      <td>Amblyomma americanum</td>\n",
       "      <td>0.402891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ZOE-0014-01</td>\n",
       "      <td>Amblyomma americanum</td>\n",
       "      <td>Amblyomma americanum</td>\n",
       "      <td>0.451165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sample_id            true_label            pred_label  pred_confidence\n",
       "0  ZOE-0014-15  Amblyomma americanum  Amblyomma americanum         0.436862\n",
       "1       150-01  Amblyomma americanum  Amblyomma americanum         0.453386\n",
       "2        69-02  Amblyomma americanum  Amblyomma americanum         0.372667\n",
       "3        31-02  Amblyomma americanum  Amblyomma americanum         0.360671\n",
       "4        43-15  Amblyomma americanum  Amblyomma americanum         0.411300\n",
       "5        34-01  Amblyomma americanum  Amblyomma americanum         0.478879\n",
       "6        61-01  Amblyomma americanum  Amblyomma americanum         0.387920\n",
       "7        40-01  Amblyomma americanum  Amblyomma americanum         0.416312\n",
       "8       465-01  Amblyomma americanum  Amblyomma americanum         0.402891\n",
       "9  ZOE-0014-01  Amblyomma americanum  Amblyomma americanum         0.451165"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Block 4 — Build X/y, Train SVM, Predict, Quick Metrics (single seed) ===\n",
    "\n",
    "# helper: turn (species, sample_id) pairs into X (embeddings) and y (labels)\n",
    "def build_xy(by_species, pairs):\n",
    "    X, y, ids = [], [], []\n",
    "    for sp, sid in pairs:\n",
    "        rec = by_species[sp][sid]          # {\"dorsal\":..., \"ventral\":...}\n",
    "        X.append(specimen_vec(rec))        # averaged dorsal+ventral embedding\n",
    "        y.append(sp)                       # species label\n",
    "        ids.append(sid)                    # specimen ID for reporting\n",
    "    return np.stack(X), np.array(y), ids\n",
    "\n",
    "# assemble train/test matrices\n",
    "Xtr, ytr, _      = build_xy(by_species, train_pairs)\n",
    "Xte, yte, te_ids = build_xy(by_species, test_pairs)\n",
    "\n",
    "# SVM pipeline (scale → RBF SVM); probability=True so we can get a confidence %\n",
    "clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm\", SVC(kernel=\"rbf\", class_weight=\"balanced\", probability=True))\n",
    "])\n",
    "\n",
    "# train + predict\n",
    "clf.fit(Xtr, ytr)\n",
    "yhat  = clf.predict(Xte)\n",
    "probs = clf.predict_proba(Xte)\n",
    "conf  = probs.max(axis=1)   # top-class probability per specimen\n",
    "\n",
    "# quick metrics\n",
    "overall_acc = accuracy_score(yte, yhat)\n",
    "\n",
    "# per-species accuracy → macro/balanced accuracy\n",
    "tmp = pd.DataFrame({\"true\": yte, \"pred\": yhat})\n",
    "per_species_acc = tmp.assign(hit=(tmp.true == tmp.pred).astype(int)).groupby(\"true\")[\"hit\"].mean()\n",
    "macro_acc = per_species_acc.mean()\n",
    "\n",
    "print(f\"Overall accuracy: {overall_acc:.3f}\")\n",
    "print(f\"Macro (balanced) accuracy: {macro_acc:.3f}\")\n",
    "\n",
    "# quick peek at a few specimen-level predictions\n",
    "preview = pd.DataFrame({\n",
    "    \"sample_id\": te_ids,\n",
    "    \"true_label\": yte,\n",
    "    \"pred_label\": yhat,\n",
    "    \"pred_confidence\": conf\n",
    "})\n",
    "display(preview.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2afb3dc",
   "metadata": {},
   "source": [
    "## Block 5 Reporting and saving results for a single seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "275f5dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Seed 0 — Overall accuracy: 0.814 | Macro (balanced): 0.814\n",
      "Per-species accuracy (sorted):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>n_test</th>\n",
       "      <th>n_correct</th>\n",
       "      <th>accuracy_species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amblyomma maculatum</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amblyomma americanum</td>\n",
       "      <td>85</td>\n",
       "      <td>76</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ixodes scapularis</td>\n",
       "      <td>134</td>\n",
       "      <td>119</td>\n",
       "      <td>0.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dermacentor variabilis</td>\n",
       "      <td>303</td>\n",
       "      <td>239</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Haemaphysalis longicornis</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     species  n_test  n_correct  accuracy_species\n",
       "0        Amblyomma maculatum       1          1             1.000\n",
       "1       Amblyomma americanum      85         76             0.894\n",
       "2          Ixodes scapularis     134        119             0.888\n",
       "3     Dermacentor variabilis     303        239             0.789\n",
       "4  Haemaphysalis longicornis      30         15             0.500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved files:\n",
      "  /Users/jayjivandas/Research_Imageomics/BioClip/tick_classification_project/results/svm_bioclip/seed_000/predictions.csv\n",
      "  /Users/jayjivandas/Research_Imageomics/BioClip/tick_classification_project/results/svm_bioclip/seed_000/per_species.csv\n",
      "  /Users/jayjivandas/Research_Imageomics/BioClip/tick_classification_project/results/svm_bioclip/seed_000/summary.json\n",
      "  /Users/jayjivandas/Research_Imageomics/BioClip/tick_classification_project/results/svm_bioclip/seed_000/split.json\n"
     ]
    }
   ],
   "source": [
    "# === Block 5 — Reporting & Save Artifacts (single seed) ===\n",
    "\n",
    "# 1) Per-specimen results table (TEST set)\n",
    "results = pd.DataFrame({\n",
    "    \"sample_id\": te_ids,\n",
    "    \"true_label\": yte,\n",
    "    \"pred_label\": yhat,\n",
    "})\n",
    "if 'conf' in locals():\n",
    "    results[\"pred_confidence\"] = conf\n",
    "results[\"correct\"] = (results.true_label == results.pred_label).astype(int)\n",
    "\n",
    "# 2) Per-species accuracy table\n",
    "per_species = (results.assign(one=1)\n",
    "               .groupby(\"true_label\")\n",
    "               .agg(n_test=(\"one\", \"sum\"),\n",
    "                    n_correct=(\"correct\", \"sum\"))\n",
    "               .assign(accuracy_species=lambda d: d.n_correct / d.n_test)\n",
    "               .reset_index()\n",
    "               .rename(columns={\"true_label\": \"species\"}))\n",
    "\n",
    "# 3) Summary metrics\n",
    "overall_acc = float(results[\"correct\"].mean())\n",
    "macro_acc   = float(per_species[\"accuracy_species\"].mean())\n",
    "\n",
    "# 4) Nicely display per-species accuracies in-notebook\n",
    "per_species_display = (per_species\n",
    "                       .sort_values([\"accuracy_species\", \"n_test\"], ascending=[False, False])\n",
    "                       .reset_index(drop=True))\n",
    "with pd.option_context('display.max_rows', None, 'display.float_format', '{:.3f}'.format):\n",
    "    print(f\"\\nSeed {SEED} — Overall accuracy: {overall_acc:.3f} | Macro (balanced): {macro_acc:.3f}\")\n",
    "    print(\"Per-species accuracy (sorted):\")\n",
    "    display(per_species_display)\n",
    "\n",
    "# 5) Prepare output folder for this seed (creates if missing)\n",
    "#    If you moved RESULTS_ROOT under ../data/processed/, keep that same path from Block 0.\n",
    "RESULTS_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "seed_dir = RESULTS_ROOT / f\"seed_{SEED:03d}\"\n",
    "seed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 6) Save CSVs\n",
    "results.to_csv(seed_dir / \"predictions.csv\", index=False)\n",
    "per_species.to_csv(seed_dir / \"per_species.csv\", index=False)\n",
    "\n",
    "# 7) Save JSON summary + split for reproducibility\n",
    "try:\n",
    "    import bioclip as _bioclip_mod\n",
    "    bioclip_version = getattr(_bioclip_mod, \"__version__\", \"unknown\")\n",
    "except Exception:\n",
    "    bioclip_version = \"unknown\"\n",
    "\n",
    "summary = {\n",
    "    \"overall_accuracy\": overall_acc,\n",
    "    \"macro_accuracy\": macro_acc,\n",
    "    \"n_test\": int(len(results)),\n",
    "    \"K\": int(K),\n",
    "    \"MIN_TOTAL\": int(MIN_TOTAL),\n",
    "    \"seed\": int(SEED),\n",
    "    \"device\": str(DEVICE),\n",
    "    \"bioclip_version\": bioclip_version,\n",
    "}\n",
    "with open(seed_dir / \"summary.json\", \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "with open(seed_dir / \"split.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"train_pairs\": train_pairs,   # list of [species, sample_id]\n",
    "        \"test_pairs\":  test_pairs\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"\\nSaved files:\")\n",
    "print(\" \", (seed_dir / \"predictions.csv\").resolve())\n",
    "print(\" \", (seed_dir / \"per_species.csv\").resolve())\n",
    "print(\" \", (seed_dir / \"summary.json\").resolve())\n",
    "print(\" \", (seed_dir / \"split.json\").resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf8e4d9",
   "metadata": {},
   "source": [
    "## Block 6 Monte Carlo, 100 seeds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c91aa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monte Carlo 5-shot SVM runs: 100%|██████████| 100/100 [00:07<00:00, 13.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Aggregate over 100 seeds ===\n",
      "       overall_accuracy  macro_accuracy\n",
      "count          100.0000        100.0000\n",
      "mean             0.8336          0.7778\n",
      "std              0.0308          0.0897\n",
      "min              0.7016          0.5275\n",
      "25%              0.8156          0.7575\n",
      "50%              0.8336          0.8117\n",
      "75%              0.8517          0.8374\n",
      "max              0.9042          0.8852\n",
      "\n",
      "Macro accuracy mean ± 95% CI: 0.7778 ± 0.0176  (n=100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Block 6 — Monte Carlo (100 seeds), aggregate results ===\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def run_one_seed(seed: int):\n",
    "    \"\"\"One complete SVM run for a given seed. Saves artifacts, returns metrics dict.\"\"\"\n",
    "    \n",
    "    # 1. Split\n",
    "    train_pairs, test_pairs, split_counts = split_once(by_species, included_species, k=K, seed=seed)\n",
    "\n",
    "    # 2. Build embeddings\n",
    "    Xtr, ytr, _      = build_xy(by_species, train_pairs)\n",
    "    Xte, yte, te_ids = build_xy(by_species, test_pairs)\n",
    "\n",
    "    # 3. Train SVM\n",
    "    clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm\", SVC(kernel=\"rbf\", class_weight=\"balanced\", probability=True))\n",
    "    ])\n",
    "    clf.fit(Xtr, ytr)\n",
    "\n",
    "    # 4. Predict\n",
    "    yhat  = clf.predict(Xte)\n",
    "    probs = clf.predict_proba(Xte)\n",
    "    conf  = probs.max(axis=1)\n",
    "\n",
    "    # 5. Per-specimen table\n",
    "    results = pd.DataFrame({\n",
    "        \"sample_id\": te_ids,\n",
    "        \"true_label\": yte,\n",
    "        \"pred_label\": yhat,\n",
    "        \"pred_confidence\": conf\n",
    "    })\n",
    "    results[\"correct\"] = (results.true_label == results.pred_label).astype(int)\n",
    "\n",
    "    # 6. Per-species table\n",
    "    per_species = (results.assign(one=1)\n",
    "                   .groupby(\"true_label\")\n",
    "                   .agg(n_test=(\"one\",\"sum\"),\n",
    "                        n_correct=(\"correct\",\"sum\"))\n",
    "                   .assign(accuracy_species=lambda d: d.n_correct / d.n_test)\n",
    "                   .reset_index()\n",
    "                   .rename(columns={\"true_label\":\"species\"}))\n",
    "\n",
    "    # 7. Metrics\n",
    "    overall_acc = float(results[\"correct\"].mean())\n",
    "    macro_acc   = float(per_species[\"accuracy_species\"].mean())\n",
    "\n",
    "    # 8. Save per-seed artifacts\n",
    "    seed_dir = RESULTS_ROOT / f\"seed_{seed:03d}\"\n",
    "    seed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    results.to_csv(seed_dir / \"predictions.csv\", index=False)\n",
    "    per_species.to_csv(seed_dir / \"per_species.csv\", index=False)\n",
    "\n",
    "    try:\n",
    "        import bioclip as _bioclip_mod\n",
    "        bioclip_version = getattr(_bioclip_mod, \"__version__\", \"unknown\")\n",
    "    except Exception:\n",
    "        bioclip_version = \"unknown\"\n",
    "\n",
    "    summary = {\n",
    "        \"overall_accuracy\": overall_acc,\n",
    "        \"macro_accuracy\": macro_acc,\n",
    "        \"n_test\": int(len(results)),\n",
    "        \"K\": int(K),\n",
    "        \"MIN_TOTAL\": int(MIN_TOTAL),\n",
    "        \"seed\": int(seed),\n",
    "        \"device\": str(DEVICE),\n",
    "        \"bioclip_version\": bioclip_version,\n",
    "        \"timestamp\": int(time.time())\n",
    "    }\n",
    "    with open(seed_dir / \"summary.json\", \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    with open(seed_dir / \"split.json\", \"w\") as f:\n",
    "        json.dump({\n",
    "            \"train_pairs\": train_pairs,\n",
    "            \"test_pairs\":  test_pairs\n",
    "        }, f, indent=2)\n",
    "\n",
    "    return {\n",
    "        \"seed\": seed,\n",
    "        \"overall_accuracy\": overall_acc,\n",
    "        \"macro_accuracy\": macro_acc,\n",
    "        \"n_test\": int(len(results))\n",
    "    }\n",
    "\n",
    "# ---- loop over seeds ----\n",
    "all_rows = []\n",
    "for s in tqdm(range(100), desc=\"Monte Carlo 5-shot SVM runs\"):\n",
    "    row = run_one_seed(s)\n",
    "    all_rows.append(row)\n",
    "\n",
    "# ---- aggregate ----\n",
    "agg = pd.DataFrame(all_rows).sort_values(\"seed\").reset_index(drop=True)\n",
    "agg.to_csv(RESULTS_ROOT / \"metrics_5shot_seeds.csv\", index=False)\n",
    "\n",
    "run_meta = {\n",
    "    \"seeds\": list(range(100)),\n",
    "    \"K\": int(K),\n",
    "    \"MIN_TOTAL\": int(MIN_TOTAL),\n",
    "    \"n_species\": int(len(included_species)),\n",
    "    \"emb_cache_dir\": str(EMB_CACHE.resolve()),\n",
    "    \"results_root\": str(RESULTS_ROOT.resolve()),\n",
    "    \"device\": str(DEVICE)\n",
    "}\n",
    "with open(RESULTS_ROOT / \"run_meta.json\", \"w\") as f:\n",
    "    json.dump(run_meta, f, indent=2)\n",
    "\n",
    "# ---- print aggregate stats ----\n",
    "with pd.option_context('display.float_format', '{:.4f}'.format):\n",
    "    print(\"\\n=== Aggregate over 100 seeds ===\")\n",
    "    print(agg[[\"overall_accuracy\",\"macro_accuracy\"]].describe())\n",
    "\n",
    "mu = agg[\"macro_accuracy\"].mean()\n",
    "sd = agg[\"macro_accuracy\"].std(ddof=1)\n",
    "n  = agg[\"macro_accuracy\"].notna().sum()\n",
    "ci95 = 1.96 * sd / np.sqrt(max(n,1))\n",
    "print(f\"\\nMacro accuracy mean ± 95% CI: {mu:.4f} ± {ci95:.4f}  (n={n})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
