# Tick Classification with BioCLIP

This project implements a full pipeline for tick species classification using [BioCLIP](https://imageomics.github.io/bioclip/) embeddings and SVM few-shot classification. It covers data cleaning, zero-shot inference, and k-shot SVM experiments with Monte Carlo evaluation.

---

## Project Structure

```
tick_classification_project/
├── config/
│   └── paths.json                  # All paths (edit this before running)
├── data/
│   ├── raw/                        # Raw CSVs and tick images (not tracked by git)
│   │   ├── AI Image Data Oct 31 2025.csv
│   │   └── Tick_Images-6_25_25/   # Original image files
│   └── processed/                  # Generated by notebook 01
│       ├── final_data.json         # Full dataset (698 specimens)
│       ├── final_data_no_ixodes.json  # Filtered dataset (599 specimens, 8 species)
│       ├── class_names.json        # 9 species labels
│       ├── class_names_no_ixodes.json  # 8 species labels (Ixodes genus removed)
│       ├── species_distribution.png
│       └── metadata_distribution.png
├── notebooks/
│   ├── 01_data_exploration.ipynb   # Data cleaning → processed JSONs
│   ├── 02_bioclip_inference.ipynb  # Zero-shot BioCLIP evaluation
│   └── 03_finetuning_svm_new.ipynb # Few-shot SVM with Monte Carlo sweep
├── src/
│   ├── tick_data_cleaning.py       # Label normalization utilities
│   └── utils/
│       └── paths.py                # Loads config/paths.json
└── results/
    └── svm/
        ├── runs/                   # Per-run prediction CSVs
        └── aggregated/             # Aggregated metrics with CIs
```

---

## Setup

### 1. Clone the repository

```bash
git clone <repo-url>
cd tick_classification_project
```

### 2. Install dependencies

There is no `requirements.txt` yet — install these packages manually into your Python environment:

```bash
pip install pybioclip scikit-learn pandas numpy torch pillow matplotlib tqdm
```

> **Note:** BioCLIP requires PyTorch. Install the appropriate version of PyTorch for your hardware first. See [pytorch.org](https://pytorch.org/get-started/locally/).

### 3. Configure paths

Edit `config/paths.json` to point to your local data:

```json
{
  "metadata_csv": "data/raw/AI Image Data Oct 31 2025.csv",
  "image_dir": "/absolute/path/to/your/tick/images",
  "processed_dir": "data/processed",
  "emb_cache_dir": "data/processed/emb_cache",
  "results_dir": "results",
  "svm_results_dir": "results/svm"
}
```

- `metadata_csv` — path to the specimen metadata CSV (relative to repo root, or absolute)
- `image_dir` — **absolute path** to the directory containing tick images (JPG/JPEG/PNG)
- All other paths can stay as relative paths from repo root

> Paths are resolved automatically by `src/utils/paths.py` — relative paths are resolved from the repo root.

### 4. Prepare your data

Place the following in `data/raw/` (not tracked by git):
- The metadata CSV (`AI Image Data Oct 31 2025.csv`)
- The tick image directory (images named `<SampleID>-01.jpg` for dorsal, `<SampleID>-02.jpg` for ventral)

---

## Running the Pipeline

Run the notebooks **in order**. Each notebook depends on outputs from the previous one.

### Notebook 01 — Data Exploration & Cleaning

**File:** `notebooks/01_data_exploration.ipynb`

**What it does:**
- Loads the specimen metadata CSV
- Deduplicates records by Sample ID
- Cross-references CSV entries with available image files
- Normalizes species labels (fixes typos, standardizes casing)
- Filters out specimens missing either dorsal or ventral images
- Builds two JSON datasets: full (9 species) and filtered (8 species, removing bare `Ixodes` genus labels)
- Saves species distribution and metadata coverage plots

**Outputs (written to `data/processed/`):**
- `final_data.json` — 1,396 image entries (698 specimens × 2 views)
- `final_data_no_ixodes.json` — 1,198 image entries (599 specimens × 2 views)
- `class_names.json` — list of 9 species
- `class_names_no_ixodes.json` — list of 8 species
- `species_distribution.png`
- `metadata_distribution.png`

---

### Notebook 02 — BioCLIP Zero-Shot Inference

**File:** `notebooks/02_bioclip_inference.ipynb`

**What it does:**
- Loads `final_data_no_ixodes.json` and `class_names_no_ixodes.json`
- Initializes a BioCLIP `CustomLabelsClassifier` with the 8 species names
- Runs zero-shot prediction on all images (no training required)
- Computes and reports:
  - Dorsal accuracy
  - Ventral accuracy
  - Highest-confidence accuracy (best of dorsal/ventral per specimen)
  - Per-class accuracy breakdown
  - Macro-accuracy for each view
- Generates full and pairwise confusion matrices

**Note:** This notebook runs BioCLIP on every image. With ~1,200 images it can take 30–60 minutes depending on hardware.

---

### Notebook 03 — Few-Shot SVM Classification

**File:** `notebooks/03_finetuning_svm_new.ipynb`

**What it does:**
- Loads class names and specimen data from the processed JSONs
- Extracts BioCLIP embeddings for each image using a caching mechanism (embeddings saved to `data/processed/emb_cache/` as `.npy` files — not tracked by git)
- For each specimen, averages the dorsal and ventral embeddings into a single vector
- Runs a **Monte Carlo k-shot SVM sweep**:
  - Shot levels: configurable (e.g. 5, 10, 20 shots per class)
  - 100 random seeds per shot level for stable estimates
  - Trains a scikit-learn SVM pipeline (`StandardScaler` + `SVC`) on the support set
  - Evaluates on the remaining specimens
- Aggregates results with 95% confidence intervals
- Generates:
  - Macro accuracy vs. shot count curves
  - Row-normalized confusion matrices per shot level
  - Per-species recall bar charts
  - Error analysis CSVs
  - HTML image gallery of misclassified specimens

**Outputs (written to `results/svm/`):**
- `runs/` — per-run prediction CSVs
- `aggregated/` — aggregated metrics with confidence intervals

**Embedding cache:** The first run embeds all images (slow). Subsequent runs reuse cached `.npy` files and are much faster.

---

## Dataset

The dataset consists of tick specimens photographed from two views (dorsal and ventral). Each specimen has a Sample ID and associated metadata.

**Species in filtered dataset (8 classes):**
| Species | Count |
|---|---|
| Dermacentor variabilis | 303 |
| Ixodes scapularis | 136 |
| Amblyomma americanum | 87 |
| Haemaphysalis longicornis | 29 |
| Ixodes cookei | 28 |
| Ixodes dentatus | 9 |
| Amblyomma maculatum | 6 |
| Dermacentor andersoni | 1 |

**Filtering applied:**
- Specimens with only one image (missing dorsal or ventral) are excluded
- Specimens labeled only as `Ixodes` (genus-level, incomplete ID) are excluded
- 17 specimens with data quality issues are excluded (identified via error analysis)

---

## Key Design Decisions

- **Dorsal + ventral averaging:** Each specimen is represented by the mean of its two BioCLIP embeddings, capturing complementary morphological views.
- **Embedding cache:** BioCLIP embeddings are hashed by image path and cached as `.npy` files. This avoids re-running the model on every experiment.
- **Shot-aware seeding:** The function `seed_for(k, run_id)` generates deterministic seeds per shot level and run, making experiments fully reproducible.
- **Monte Carlo evaluation:** 100 random train/test splits per shot level give stable accuracy estimates with confidence intervals.

---

## Source Utilities

### `src/utils/paths.py`
Loads `config/paths.json` and resolves all paths relative to the repo root. Import it in any notebook like:
```python
import sys
from pathlib import Path
repo_root = Path.cwd().resolve().parent  # assumes notebook is in notebooks/
sys.path.insert(0, str(repo_root))
from src.utils.paths import load_paths
paths = load_paths()
```

### `src/tick_data_cleaning.py`
Provides label normalization functions:
- `normalize_spaces(s)` — strips Unicode spaces and invisible characters
- `fix_label_minimal(raw)` — fixes the `Dermacentor variablis` typo and standardizes binomial casing
- `load_and_clean_csv(csv_path)` — convenience loader that applies cleaning to a CSV

---

## What is Tracked by Git

| Path | Tracked |
|---|---|
| `config/paths.json` | Yes |
| `data/raw/` | **No** (gitignored) |
| `data/processed/emb_cache/` | **No** (gitignored) |
| `data/processed/*.json` | Yes |
| `data/processed/*.png` | Yes |
| `notebooks/` | Yes |
| `src/` | Yes |
| `results/` | Yes |
| `*.html` (galleries) | **No** (gitignored) |
